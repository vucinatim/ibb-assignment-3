{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors to draw rectangles in BGR\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # opencv object that will detect faces\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model to face classification\n",
    "# model was created in me_not_me_classifier.ipynb notebook\n",
    "model_name = 'face_classifier_aug.h5'\n",
    "\n",
    "face_classifier = keras.models.load_model(f'models/{model_name}')\n",
    "class_names = ['me', 'not_me']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_image(img, x, y, w, h, k=0.1):\n",
    "    '''\n",
    "    Function, that return cropped image from 'img'\n",
    "    If k=0 returns image, cropped from (x, y) (top left) to (x+w, y+h) (bottom right)\n",
    "    If k!=0 returns image, cropped from (x-k*w, y-k*h) to (x+k*w, y+(1+k)*h)\n",
    "    After getting the desired image resize it to 250x250.\n",
    "    And converts to tensor with shape (1, 250, 250, 3)\n",
    "\n",
    "    Parameters:\n",
    "        img (array-like, 2D): The original image\n",
    "        x (int): x coordinate of the upper-left corner\n",
    "        y (int): y coordinate of the upper-left corner\n",
    "        w (int): Width of the desired image\n",
    "        h (int): Height of the desired image\n",
    "        k (float): The coefficient of expansion of the image\n",
    "\n",
    "    Returns:\n",
    "        image (tensor with shape (1, 250, 250, 3))\n",
    "    '''\n",
    "\n",
    "    # The next code block checks that coordinates will be non-negative\n",
    "    # (in case if desired image is located in top left corner)\n",
    "    if x - k*w > 0:\n",
    "        start_x = int(x - k*w)\n",
    "    else:\n",
    "        start_x = x\n",
    "    if y - k*h > 0:\n",
    "        start_y = int(y - k*h)\n",
    "    else:\n",
    "        start_y = y\n",
    "\n",
    "    end_x = int(x + (1 + k)*w)\n",
    "    end_y = int(y + (1 + k)*h)\n",
    "\n",
    "    face_image = img[start_y:end_y,\n",
    "                     start_x:end_x]\n",
    "    face_image = tf.image.resize(face_image, [250, 250])\n",
    "    # shape from (250, 250, 3) to (1, 250, 250, 3)\n",
    "    face_image = np.expand_dims(face_image, axis=0)\n",
    "    return face_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to the camera was successfully obtained\n",
      "Streaming started - to quit press ESC\n",
      "Streaming ended\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)  # webcamera\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Unable to access the camera\")\n",
    "else:\n",
    "    print(\"Access to the camera was successfully obtained\")\n",
    "\n",
    "print(\"Streaming started - to quit press ESC\")\n",
    "while True:\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(100, 100),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # for each face on the image detected by OpenCV\n",
    "        # get extended image of this face\n",
    "        face_image = get_extended_image(frame, x, y, w, h, 0.5)\n",
    "\n",
    "        # classify face and draw a rectangle around the face\n",
    "        # green for positive class and red for negative\n",
    "        result = face_classifier.predict(face_image)\n",
    "        prediction = class_names[np.array(\n",
    "            result[0]).argmax(axis=0)]  # predicted class\n",
    "        confidence = np.array(result[0]).max(axis=0)  # degree of confidence\n",
    "\n",
    "        if prediction == 'me':\n",
    "            color = GREEN\n",
    "        else:\n",
    "            color = RED\n",
    "        # draw a rectangle around the face\n",
    "        cv2.rectangle(frame,\n",
    "                      (x, y),  # start_point\n",
    "                      (x+w, y+h),  # end_point\n",
    "                      color,\n",
    "                      2)  # thickness in px\n",
    "        cv2.putText(frame,\n",
    "                    # text to put\n",
    "                    \"{:6} - {:.2f}%\".format(prediction, confidence*100),\n",
    "                    (x, y),\n",
    "                    cv2.FONT_HERSHEY_PLAIN,  # font\n",
    "                    2,  # fontScale\n",
    "                    color,\n",
    "                    2)  # thickness in px\n",
    "\n",
    "    # display the resulting frame\n",
    "    cv2.imshow(\"Face detector - to quit press ESC\", frame)\n",
    "\n",
    "    # Exit with ESC\n",
    "    key = cv2.waitKey(1)\n",
    "    if key % 256 == 27:  # ESC code\n",
    "        break\n",
    "\n",
    "\n",
    "# when everything done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Streaming ended\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "787445a66def3a2acb2c4791d206a7f666e371ba7d09d2ffe3dc1b676f1645fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
